#!/usr/bin/env python
# -*- coding: utf-8 -*-
import os
import hashlib
import joblib
import pandas as pd
import numpy as np
import re
from datetime import datetime
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from google.colab import drive

drive.mount('/content/drive', force_remount=True)

DRIVE_MODEL_DIR = "/content/drive/MyDrive/ai_model/versions"
CSV_FILE_PATH = "/content/drive/MyDrive/ai_model/joongna_all_categories.csv"

class EnhancedEncoder(LabelEncoder):
    def fit_transform(self, data):
        data = super().fit_transform([str(x).lower().strip() for x in data])
        return data

class ConditionEncoder:
    def transform(self, data):
        result = []
        for x in data:
            x_str = str(x).lower().strip()
            if "ì¤‘ê³ " in x_str:
                result.append(0)
            elif "ìƒˆ" in x_str or "ë¯¸ê°œë´‰" in x_str:
                result.append(1)
            else:
                result.append(0)
        return result
    def fit_transform(self, data):
        return self.transform(data)

def get_data_hash():
    with open(CSV_FILE_PATH, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

def refine_model_name(model_name, keyword):
    refined = re.sub(re.escape(keyword), '', model_name, flags=re.IGNORECASE).strip()
    return refined if refined != "" else model_name

def train_new_model():
    current_hash = get_data_hash()
    latest_version = None
    try:
        with open(os.path.join(DRIVE_MODEL_DIR, 'LATEST'), 'r') as f:
            latest_version = f.read().strip()
            latest_hash = joblib.load(os.path.join(DRIVE_MODEL_DIR, f"v{latest_version}", 'data_hash.joblib'))
            if latest_hash == current_hash:
                print("ğŸ”„ ë°ì´í„° ë³€ê²½ ì—†ìŒ - í•™ìŠµ ìŠ¤í‚µ")
                return
    except Exception:
        pass

    if input("ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() != 'y':
        return

    df = pd.read_csv(CSV_FILE_PATH, dtype=str, encoding='utf-8').dropna()
    df['ê°€ê²©'] = df['ê°€ê²©'].str.replace('[^\d]', '', regex=True).astype(int)

    for col in ['í‚¤ì›Œë“œ', 'ì—…ì¢…', 'ëª¨ë¸ëª…', 'ìƒí’ˆìƒíƒœ']:
        df[col] = df[col].str.lower().str.strip().fillna('unknown').str.replace('[^a-z0-9ê°€-í£ ]', '', regex=True)

    df['í‚¤ì›Œë“œ'] = df['í‚¤ì›Œë“œ'].replace('', np.nan).fillna(df['ì—…ì¢…'])
    df['ëª¨ë¸ëª…'] = df.apply(lambda row: refine_model_name(row['ëª¨ë¸ëª…'], row['í‚¤ì›Œë“œ']) if row['í‚¤ì›Œë“œ'] in row['ëª¨ë¸ëª…'] else row['ëª¨ë¸ëª…'], axis=1)
    
    df = df[~df['ëª¨ë¸ëª…'].str.contains("êµ¬ë§¤")]

    
    if 'ì¡°íšŒìˆ˜' in df.columns:
        df['ì¡°íšŒìˆ˜'] = df['ì¡°íšŒìˆ˜'].str.replace('[^\d]', '', regex=True)
        df['ì¡°íšŒìˆ˜'] = pd.to_numeric(df['ì¡°íšŒìˆ˜'], errors='coerce').fillna(0).astype(int)
    else:
        df['ì¡°íšŒìˆ˜'] = 0

    
    encoders = {
        'keyword': EnhancedEncoder(),
        'upjong': EnhancedEncoder(),
        'model': EnhancedEncoder(),
        'condition': ConditionEncoder()
    }
    df['í‚¤ì›Œë“œ_enc'] = encoders['keyword'].fit_transform(df['í‚¤ì›Œë“œ'])
    df['ì—…ì¢…_enc'] = encoders['upjong'].fit_transform(df['ì—…ì¢…'])
    df['ëª¨ë¸ëª…_enc'] = encoders['model'].fit_transform(df['ëª¨ë¸ëª…'])
    df['ìƒí’ˆìƒíƒœ_enc'] = encoders['condition'].fit_transform(df['ìƒí’ˆìƒíƒœ'])

    
    df['freq'] = df.groupby(['ì—…ì¢…', 'í‚¤ì›Œë“œ', 'ëª¨ë¸ëª…'])['ëª¨ë¸ëª…'].transform('count')
    df['norm_freq'] = df.groupby('ì—…ì¢…')['freq'].transform(lambda x: x / x.max())
    df['norm_price'] = df.groupby('ì—…ì¢…')['ê°€ê²©'].transform(lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8))
    df['norm_view'] = df.groupby('ì—…ì¢…')['ì¡°íšŒìˆ˜'].transform(lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8))
    # íŒë§¤í™•ë¥  ê³„ì‚°: ì¸ê¸°ë„(ë¹ˆë„), ê°€ê²©, ì¡°íšŒìˆ˜, ìƒí’ˆìƒíƒœë¥¼ ë°˜ì˜
    df['íŒë§¤í™•ë¥ '] = (0.4 * df['norm_freq'] +
                      0.2 * (1 - df['norm_price']) +
                      0.2 * (1 - df['norm_view']) +
                      0.2 * (1 - df['ìƒí’ˆìƒíƒœ_enc']))

    
    median_view_dict = df.groupby('ì—…ì¢…')['ì¡°íšŒìˆ˜'].median().to_dict()

    # ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ (XGBoost ì‚¬ìš©)
    X_price = df[['í‚¤ì›Œë“œ_enc', 'ì—…ì¢…_enc', 'ëª¨ë¸ëª…_enc', 'ìƒí’ˆìƒíƒœ_enc']]
    y_price = df['ê°€ê²©']
    X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_price, y_price, test_size=0.2, random_state=42)
    price_model = XGBRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)
    price_model.fit(X_train_p, y_train_p)

    # íŒë§¤ í™•ë¥  ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
    X_sales = df[['í‚¤ì›Œë“œ_enc', 'ì—…ì¢…_enc', 'ëª¨ë¸ëª…_enc', 'ìƒí’ˆìƒíƒœ_enc', 'ê°€ê²©', 'ì¡°íšŒìˆ˜']]
    y_sales = df['íŒë§¤í™•ë¥ ']
    X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sales, y_sales, test_size=0.2, random_state=42)
    sales_model = XGBRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)
    sales_model.fit(X_train_s, y_train_s)

    version_id = datetime.now().strftime("%Y%m%d-%H%M%S")
    save_path = os.path.join(DRIVE_MODEL_DIR, f"v{version_id}")
    os.makedirs(save_path, exist_ok=True)
    
    joblib.dump(price_model, os.path.join(save_path, 'price_model.joblib'))
    joblib.dump(sales_model, os.path.join(save_path, 'sales_model.joblib'))
    joblib.dump(encoders, os.path.join(save_path, 'encoders.joblib'))
    joblib.dump(median_view_dict, os.path.join(save_path, 'median_view_dict.joblib'))
    joblib.dump(current_hash, os.path.join(save_path, 'data_hash.joblib'))
    
    with open(os.path.join(DRIVE_MODEL_DIR, 'LATEST'), 'w') as f:
        f.write(version_id)

    print(f"ìƒˆ ëª¨ë¸ v{version_id} ì €ì¥")

if __name__ == "__main__":
    train_new_model()
